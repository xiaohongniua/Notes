{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting ./MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting ./MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting ./MNIST_data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "import  tensorflow as tf\n",
    "import  input_data\n",
    "#define get_data\n",
    "mnist=input_data.read_data_sets(\"./MNIST_data\",one_hot=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_rate=0.001\n",
    "train_step=1000\n",
    "batch_size=1280\n",
    "display_step=100\n",
    "\n",
    "#the num of char\n",
    "sequence_length=28\n",
    "#the dimention of the vector representing each char\n",
    "frame_size=28\n",
    "\n",
    "#the dimention of hidden state\n",
    "hidden_num=100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "hiden num is the dimention of the hidden layer,not the num of hidden cells.general \n",
    "every inout[batch,seq_length,depth] will have a output[batch,seq_length,hidden_num],\n",
    "you can get the final output:output[:,-1,:]=>[batch,hidden_num]\n",
    "in this exampple,then you can changed the dimention to class num by w*final_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_classes=10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#定义输入,输出\n",
    "x=tf.placeholder(dtype=tf.float32,shape=[None,sequence_length*frame_size],name=\"inputx\")\n",
    "y=tf.placeholder(dtype=tf.float32,shape=[None,n_classes],name=\"expected_y\")\n",
    "#定义权值\n",
    "weights=tf.Variable(tf.truncated_normal(shape=[hidden_num,n_classes]))\n",
    "bias=tf.Variable(tf.zeros(shape=[n_classes]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def RNN(x,weights,bias):\n",
    "    x=tf.reshape(x,shape=[-1,sequence_length,frame_size])\n",
    "    rnn_cell=tf.nn.rnn_cell.BasicRNNCell(hidden_num)\n",
    "    #initial_state = rnn_cell.zero_state(batch_size, dtype=tf.float32)\n",
    "    #init_state=tf.zeros(shape=[batch_size,rnn_cell.state_size])\n",
    "    #init_state=rnn_cell.zero_state(batch_size, dtype=tf.float32)\n",
    "    # 其实这是一个深度RNN网络,对于每一个长度为n的序列[x1,x2,x3,...,xn]的每一个xi,都会在深度方向跑一遍RNN,跑上hidden_num个隐层单元\n",
    "    #output,states=tf.nn.dynamic_rnn(rnn_cell,x,initial_state=init_state,dtype=tf.float32)\n",
    "    output,states=tf.nn.dynamic_rnn(rnn_cell,x,dtype=tf.float32)\n",
    "    return tf.nn.softmax(tf.matmul(output[:,-1,:],weights)+bias,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "predy=RNN(x,weights,bias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-8-0df9dfaacf9e>:1: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "\n",
      "Future major versions of TensorFlow will allow gradients to flow\n",
      "into the labels input on backprop by default.\n",
      "\n",
      "See tf.nn.softmax_cross_entropy_with_logits_v2.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cost=tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=predy,labels=y))\n",
    "train=tf.train.AdamOptimizer(train_rate).minimize(cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "correct_pred=tf.equal(tf.argmax(predy,1),tf.argmax(y,1))\n",
    "accuracy=tf.reduce_mean(tf.to_float(correct_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/xhliu/miniconda3/lib/python3.6/site-packages/tensorflow/python/util/tf_should_use.py:118: initialize_all_variables (from tensorflow.python.ops.variables) is deprecated and will be removed after 2017-03-02.\n",
      "Instructions for updating:\n",
      "Use `tf.global_variables_initializer` instead.\n"
     ]
    }
   ],
   "source": [
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth=True\n",
    "sess = tf.Session(config=config)\n",
    "sess.run(tf.initialize_all_variables())\n",
    "step=1\n",
    "testx,testy=mnist.test.next_batch(batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 0.78828126 1.6798966\n",
      "200 0.9 1.5646069\n",
      "300 0.9242188 1.542869\n",
      "400 0.94140625 1.5247853\n",
      "500 0.940625 1.5235918\n",
      "600 0.94375 1.5192797\n",
      "700 0.95625 1.5098501\n",
      "800 0.95625 1.5067168\n",
      "900 0.95234376 1.5137138\n"
     ]
    }
   ],
   "source": [
    "while step<train_step:\n",
    "    batch_x,batch_y=mnist.train.next_batch(batch_size)\n",
    "#    batch_x=tf.reshape(batch_x,shape=[batch_size,sequence_length,frame_size])\n",
    "    _loss,__=sess.run([cost,train],feed_dict={x:batch_x,y:batch_y})\n",
    "    if step % display_step ==0:\n",
    "        acc,loss=sess.run([accuracy,cost],feed_dict={x:testx,y:testy})\n",
    "        print(step,acc,loss)\n",
    "    step+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
